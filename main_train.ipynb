{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch_directml\n",
    "import pandas as pd\n",
    "\n",
    "# device = torch_directml.device()\n",
    "device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "moves = pd.read_csv(\"kfm_moves.csv\")\n",
    "all_moves = moves['Value'].to_numpy()\n",
    "\n",
    "data_dir = 'data'\n",
    "learning_rate = 1e-3\n",
    "batch_size = 8\n",
    "num_epochs = 50\n",
    "hidden_dim = 64\n",
    "# frame player all status count\n",
    "num_classes = len(all_moves)\n",
    "# game status args count\n",
    "frame_status_args = 19\n",
    "frame_window_length = 10\n",
    "\n",
    "print(f\"Total moves: {len(all_moves)}\")\n",
    "\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, data_dir, frame_window_length=10):\n",
    "        # self.files = sorted(glob.glob(os.path.join(data_dir, \"*.npy\")))\n",
    "        self.files = [os.path.join(data_dir, '0.npy')]\n",
    "        self.frame_window_length = frame_window_length\n",
    "        self.samples = []\n",
    "\n",
    "        assert len(self.files) > 0, f\"No .npy files found in {data_dir}\"\n",
    "        \n",
    "        print(f\"Found {len(self.files)} data files.\")\n",
    "        self._build_samples()\n",
    "    \n",
    "    def _build_samples(self):\n",
    "        for filepath in self.files:\n",
    "            data = np.load(filepath)\n",
    "            N = data.shape[0]\n",
    "\n",
    "            filename = os.path.basename(filepath)\n",
    "            move = int(os.path.splitext(filename)[0]) - 1\n",
    "            move = torch.tensor(move, dtype=torch.long)\n",
    "\n",
    "            for start_idx in range(N - self.frame_window_length):\n",
    "                end_idx = start_idx + self.frame_window_length\n",
    "                window = data[start_idx:end_idx]\n",
    "                window = torch.tensor(window, dtype=torch.float32)\n",
    "\n",
    "                active_move = (np.abs(torch.tensor(all_moves) - move) < 0.1).float()\n",
    "                self.samples.append((window, active_move))\n",
    "        \n",
    "        print(f\"Total samples generated: {len(self.samples)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, (hidden, _) = self.lstm(x)\n",
    "        out = self.fc(hidden[-1])\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    datas, labels = zip(*batch)\n",
    "    return torch.stack(datas), torch.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc3225",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SimpleDataset(data_dir, frame_window_length=frame_window_length)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5529569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleClassifier(frame_status_args, hidden_dim, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_datas, batch_labels in dataloader:\n",
    "        batch_datas = batch_datas.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_datas)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += batch_labels.size(0)\n",
    "        correct += predicted.eq(batch_labels.argmax(dim=1)).sum().item()\n",
    "    \n",
    "    acc = 100. * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Acc: {acc:.2f}%\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Training finished. Model saved to model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fight-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
